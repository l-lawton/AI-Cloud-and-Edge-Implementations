{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amita-kapoor/UO-Artificial-Intelligence-Cloud-and-Edge-Implementations/blob/master/Excercise_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZDq2nwZp2dv"
      },
      "source": [
        "## Classification Exercises\n",
        "\n",
        "For these exercises use the GPU in Google Colab. To enable GPU go to top menu bar in **EDIT** menu go to **NoteBook Settings**. Once you click it a window opens, in the hardware accelerator dropdown menu choose GPU. \n",
        "\n",
        "![alt](https://drive.google.com/uc?id=1rZf9pvb5rqY4rFwYqUhdmPkSrzaXBhPg)\n",
        "\n",
        "### Introduction\n",
        "\n",
        "We have already learned about Neural Networks and discussed Multilayered Perceptrons in depth. In this exercise, we will be testing our understanding of the underlying concepts with special emphasis to [Hyperparameter tuning](https://towardsdatascience.com/understanding-hyperparameters-and-its-optimisation-techniques-f0debba07568). \n",
        "\n",
        "After doing these exercises, you would be able to better understand:\n",
        "\n",
        "* The architecture of a neural network\n",
        "* The parameters (training) of a neural network and how they change with changing architecture.\n",
        "* Hyperparameter tuning: batch size, number of hidden units and optimizers.\n",
        "\n",
        "We encourage you to work with other hyperparameters as well like learning rate, number of layers, activation functions etc.  And in the end there is an optional exercise, where you can see if what you observe for the MNIST dataset is true for other dataset as well.\n",
        "\n",
        "The Notebook is divided in three parts: Building the Model, Reading the dataset and Hyperparameters. It contains five exercises in total and one additional optional exercise:\n",
        "\n",
        "* [Exercise 1](#ex_1)\n",
        "* [Exercise 2](#ex_2)\n",
        "* [Exercise 3](#ex_3)\n",
        "* [Exercise 4](#ex_4)\n",
        "* [Exercise 5](#ex_5)\n",
        "* [Optional Exercise](#ex_O)\n",
        "\n",
        "\n",
        "You have to do all the five exercises. Run the code given with each exercise and write down your answer just below each exercise. Wish you all the best.\n",
        "\n",
        "\n",
        "### Part 1: Building the model\n",
        "Below we define a function to built a neural network model using TensorFlow Keras. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3mhZ0xlMRqO6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "def built_model(input_shape, n_hidden, nb_classes, optimizer='SGD'):\n",
        "  '''\n",
        "  The function builds a fully connected neural network with two hidden layers\n",
        "  Arguments:\n",
        "  input_shape: The number of inputs to the neural network\n",
        "  n_hidden: Number of hidden neurons in the hidden layers\n",
        "  nb_classes: Number of neurons in the output layer\n",
        "  optimizer: The optimizer used to train the model. \n",
        "  By default we use Stochastic Gradient Descent.\n",
        "  \n",
        "  Returns:\n",
        "  The function returns A model with loss and optimizer defined\n",
        "  '''  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  ## First Hidden layer  \n",
        "  model.add(keras.layers.Dense(n_hidden,\n",
        "       input_shape=(input_shape,),\n",
        "       name='dense_layer', activation='relu'))\n",
        "    \n",
        "  ## Second Hidden Layer\n",
        "  model.add(keras.layers.Dense(n_hidden,\n",
        "        name='dense_layer_2', activation='relu'))\n",
        "    \n",
        "  ## Output Layer  \n",
        "  model.add(keras.layers.Dense(nb_classes,\n",
        "        name='dense_layer_3', activation='softmax'))\n",
        "    \n",
        "  ## Define loss and optimizer \n",
        "  model.compile(optimizer=optimizer, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5E0fCSDrwu_"
      },
      "source": [
        "<a id='ex_1'></a>\n",
        "**Exercise 1** What should be the values of the arguments `INPUT_SHAPE`: the number of input units, `N_HIDDEN`: the number of hidden units, and `NB_CLASSES`: the number of output units, if we want to build a model using `built_model` function with the specifications given in the figure:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1pcj2sHJK6CmhMjUo43AMNBxnU4ixQne3)\n",
        "\n",
        "\n",
        "\n",
        "To build this network we used TensorFlow Keras `plot_model` function available in `utils` model. You can learn more about the function from [TensorFlow docs](https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sBfRdV8ARuCe"
      },
      "outputs": [],
      "source": [
        "# Task to do\n",
        "INPUT_SHAPE = 5\n",
        "N_HIDDEN = 10\n",
        "NB_CLASSES = 2  \n",
        "\n",
        "\n",
        "## Do not change anything below\n",
        "assert(INPUT_SHAPE == 5), \"Input shape incorrect\"\n",
        "assert(N_HIDDEN == 10), \"Number of hidden neurons incorrect\"\n",
        "assert(NB_CLASSES == 2), \"Number of output units incorrect\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s00urUTcqfZR"
      },
      "outputs": [],
      "source": [
        "model = built_model(INPUT_SHAPE, N_HIDDEN,NB_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTccrPMNyZF5"
      },
      "source": [
        "<a id='ex_2'></a>\n",
        "**Exercise 2** Based on the input, hidden and output units what are the total number of trainable parameters in this model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DchkRcAyXM6",
        "outputId": "9f8d81c1-d860-4cb9-b380-b5fd19a93554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters in the model are 192\n"
          ]
        }
      ],
      "source": [
        "# Task to do\n",
        "trainable_parameters = 192\n",
        "\n",
        "## Do not change anything below\n",
        "assert trainable_parameters==model.count_params(), \"Your answer is incorrect\"\n",
        "print(\"Number of trainable parameters in the model are\", trainable_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g33IqZrGzLeW"
      },
      "source": [
        "Good work! Let us now visualize the summary of the model created. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4OteoBfx_QH",
        "outputId": "d7b02035-abe4-4070-9c15-9ab848803f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 10)                60        \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 10)                110       \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 192\n",
            "Trainable params: 192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qeqEE5A3MQl"
      },
      "source": [
        "### Part 2: Reading the dataset\n",
        "\n",
        "We will continue with the MNIST dataset. \n",
        "\n",
        "###### Just run the cells in this part of the notebook. Do not change anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D3OEjwzLyBoO"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "94uZnloL4-lB"
      },
      "outputs": [],
      "source": [
        "# Processing the data\n",
        "assert(len(X_train.shape)==3), \"The input data is not of the right shape\"\n",
        "RESHAPED = X_train.shape[1]*X_train.shape[2]\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJIMT6sT5Wtd",
        "outputId": "f85e1b2f-334d-4f82-b735-fefb682e2caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Data Normalization\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIRrNUTj4h_R"
      },
      "source": [
        "For the MNIST dataset the number of input and number of output units are fixed. However we can choose different values of hidden units. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "si1FflpL3_hj"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = RESHAPED\n",
        "NB_CLASSES = len(set(Y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ISwN58Q48a03"
      },
      "outputs": [],
      "source": [
        "# one-hot encode\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gjEx-hQ6Xsv"
      },
      "source": [
        "### Part 3: Hyperparameters\n",
        "\n",
        "<a id='ex_3'></a>\n",
        "**Exercise 3:** The aim of this exercise is to understand the affect of changing number of hidden units on the model performance. Change the number of hidden units, and train the model. Compare the model performance in terms of accuracy. What do you understand from this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWggLtWe7MUR"
      },
      "source": [
        "**Answer** Please type your answer here (Double click to edit)\n",
        "\n",
        "An increase in the hidden units leads to a higher accuracy over the same unit of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qscy8jLk6BEA"
      },
      "outputs": [],
      "source": [
        "# Task to do choose different values for number of hidden units (minimum five different values)\n",
        "N_HIDDEN = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yG8aKH37krD",
        "outputId": "0fb57267-0ec7-4112-bdcd-406eeeb8ac6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1951 - accuracy: 0.1621 - val_loss: 2.1146 - val_accuracy: 0.2129\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.0736 - accuracy: 0.1793 - val_loss: 2.0143 - val_accuracy: 0.1749\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9938 - accuracy: 0.1876 - val_loss: 1.9453 - val_accuracy: 0.2096\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9282 - accuracy: 0.2430 - val_loss: 1.8755 - val_accuracy: 0.2592\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.8515 - accuracy: 0.2844 - val_loss: 1.7875 - val_accuracy: 0.3124\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.7543 - accuracy: 0.3236 - val_loss: 1.6828 - val_accuracy: 0.3433\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.6543 - accuracy: 0.3515 - val_loss: 1.5918 - val_accuracy: 0.3641\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5783 - accuracy: 0.3736 - val_loss: 1.5294 - val_accuracy: 0.3759\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5275 - accuracy: 0.3837 - val_loss: 1.4866 - val_accuracy: 0.3845\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4913 - accuracy: 0.3933 - val_loss: 1.4548 - val_accuracy: 0.3993\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4629 - accuracy: 0.4067 - val_loss: 1.4302 - val_accuracy: 0.4007\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4387 - accuracy: 0.4239 - val_loss: 1.4053 - val_accuracy: 0.4552\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4164 - accuracy: 0.4488 - val_loss: 1.3816 - val_accuracy: 0.4789\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3959 - accuracy: 0.4583 - val_loss: 1.3612 - val_accuracy: 0.4804\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3771 - accuracy: 0.4682 - val_loss: 1.3416 - val_accuracy: 0.4705\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3601 - accuracy: 0.4693 - val_loss: 1.3252 - val_accuracy: 0.4837\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3447 - accuracy: 0.4813 - val_loss: 1.3096 - val_accuracy: 0.4914\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3308 - accuracy: 0.4869 - val_loss: 1.2962 - val_accuracy: 0.4958\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3177 - accuracy: 0.4913 - val_loss: 1.2836 - val_accuracy: 0.4972\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3040 - accuracy: 0.5201 - val_loss: 1.2696 - val_accuracy: 0.5595\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2880 - accuracy: 0.5574 - val_loss: 1.2535 - val_accuracy: 0.5746\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2684 - accuracy: 0.5689 - val_loss: 1.2362 - val_accuracy: 0.5836\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2498 - accuracy: 0.5745 - val_loss: 1.2204 - val_accuracy: 0.5902\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2349 - accuracy: 0.5763 - val_loss: 1.2063 - val_accuracy: 0.5901\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2223 - accuracy: 0.5809 - val_loss: 1.1945 - val_accuracy: 0.5919\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2117 - accuracy: 0.5841 - val_loss: 1.1829 - val_accuracy: 0.5987\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2026 - accuracy: 0.5839 - val_loss: 1.1733 - val_accuracy: 0.5962\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1935 - accuracy: 0.5855 - val_loss: 1.1662 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1860 - accuracy: 0.5872 - val_loss: 1.1624 - val_accuracy: 0.6011\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1793 - accuracy: 0.5879 - val_loss: 1.1563 - val_accuracy: 0.5943\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1727 - accuracy: 0.5899 - val_loss: 1.1514 - val_accuracy: 0.6016\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1670 - accuracy: 0.5906 - val_loss: 1.1407 - val_accuracy: 0.6018\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1613 - accuracy: 0.5933 - val_loss: 1.1368 - val_accuracy: 0.6023\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1559 - accuracy: 0.5935 - val_loss: 1.1315 - val_accuracy: 0.5989\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1512 - accuracy: 0.5930 - val_loss: 1.1274 - val_accuracy: 0.6117\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1456 - accuracy: 0.5955 - val_loss: 1.1226 - val_accuracy: 0.6059\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1405 - accuracy: 0.5970 - val_loss: 1.1149 - val_accuracy: 0.6131\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1348 - accuracy: 0.5956 - val_loss: 1.1122 - val_accuracy: 0.6079\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1283 - accuracy: 0.5986 - val_loss: 1.1015 - val_accuracy: 0.6027\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1217 - accuracy: 0.5992 - val_loss: 1.0931 - val_accuracy: 0.6148\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1144 - accuracy: 0.6018 - val_loss: 1.0863 - val_accuracy: 0.6124\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1070 - accuracy: 0.6034 - val_loss: 1.0768 - val_accuracy: 0.6164\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0996 - accuracy: 0.6059 - val_loss: 1.0720 - val_accuracy: 0.6235\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0920 - accuracy: 0.6079 - val_loss: 1.0633 - val_accuracy: 0.6221\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0851 - accuracy: 0.6083 - val_loss: 1.0559 - val_accuracy: 0.6278\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0789 - accuracy: 0.6101 - val_loss: 1.0492 - val_accuracy: 0.6299\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0730 - accuracy: 0.6122 - val_loss: 1.0469 - val_accuracy: 0.6295\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0677 - accuracy: 0.6124 - val_loss: 1.0393 - val_accuracy: 0.6308\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0627 - accuracy: 0.6118 - val_loss: 1.0389 - val_accuracy: 0.6274\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0583 - accuracy: 0.6161 - val_loss: 1.0343 - val_accuracy: 0.6309\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.0673 - accuracy: 0.6177\n",
            "Test accuracy: 61.77 %\n"
          ]
        }
      ],
      "source": [
        "## Do not change anything below\n",
        "model = built_model(INPUT_SHAPE,N_HIDDEN, NB_CLASSES)\n",
        "history = model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=128, epochs=50,\n",
        "\t\tverbose=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: {:.2f} %'.format(test_acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfMXnlJA02g"
      },
      "source": [
        "<a id='ex_4'></a>\n",
        "**Exercise 4:** Let us now repeat the same after changing the batch size (minimum 5 different values). Compare the model performance in terms of accuracy. What do you understand from this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z0TctxjB0KA"
      },
      "source": [
        "**Answer** Please type your answer here (Double click to edit)\n",
        "\n",
        "An increase in the batch size leads to a higher accuracy over the same unit of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TXO0QZtS_mQ_"
      },
      "outputs": [],
      "source": [
        "# Task to do choose different values for batch size (minimum five different values)\n",
        "BATCH_SIZE =  1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "S1CVvMthBmWr",
        "outputId": "e5b01c29-2098-44a8-a3fa-21cd8a92852e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  639/48000 [..............................] - ETA: 1:42 - loss: 1.2592 - accuracy: 0.5931"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c4a64edaa1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Do not change anything below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(X_train, Y_train,\n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \t\tverbose=1, validation_split=0.2)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m           \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1250\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## Do not change anything below\n",
        "model = built_model(INPUT_SHAPE,128, NB_CLASSES)\n",
        "history = model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=50,\n",
        "\t\tverbose=1, validation_split=0.2)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: {:.2f} %'.format(test_acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L802oqkCBg8"
      },
      "source": [
        "<a id='ex_5'></a>\n",
        "**Exercise 5:** And now we do the same with different [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) available in TensorFlow. Change the optimizers and compare the model performance in terms of accuracy. What do you understand from this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M0Dx7O2CEW8"
      },
      "source": [
        "**Answer** Please type your answer here (Double click to edit)\n",
        "\n",
        "Adadelta accuracy: 85.65%.\n",
        "Adagrad accuracy: 93.24%.\n",
        "Nadam accuracy: 97.95%.\n",
        "Adamax accuracy: 97.96%.\n",
        "FTRL accuracy: 11.35%.\n",
        "\n",
        "Adamax has the highest accuracy, meaning a first-order gradient-based optimization method is most accurate out of the 5 methods used.\n",
        "\n",
        "Ftrl is least accurate, meaning a method meant for shallow models isn't as valuable with this deep learning algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2DsZiC8CB7j5"
      },
      "outputs": [],
      "source": [
        "# Task to do choose different optimizers\n",
        "opt =   tf.keras.optimizers.experimental.Ftrl() #Choose from available optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkcTxGl4CqK5",
        "outputId": "4d7546de-96f3-42bc-d066-6e21c13a5cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 2.3027 - accuracy: 0.1135 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3023 - accuracy: 0.1140 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3022 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3021 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3020 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3020 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3019 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3019 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3018 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3018 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3017 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3017 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3016 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3016 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3016 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3016 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3016 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3015 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3014 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3012 - accuracy: 0.1135\n",
            "Test accuracy: 11.35 %\n"
          ]
        }
      ],
      "source": [
        "## Do not change anything below\n",
        "N_HIDDEN = 128\n",
        "model = built_model(INPUT_SHAPE,N_HIDDEN, NB_CLASSES, opt)\n",
        "history = model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=128, epochs=50,\n",
        "\t\tverbose=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: {:.2f} %'.format(test_acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-46TwuMnDdIB"
      },
      "source": [
        "<a id='ex_O'></a>\n",
        "### Optional Exercise: Fashion MNIST\n",
        "\n",
        "Repeat the above exercises (3-5) with different dataset. You can use Fashion MNIST another popular ML dataset. Are the results same? Comment.\n",
        "\n",
        "To download fashion mnist you can use the following code:\n",
        "\n",
        "```\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqc0ID8XDLCN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}